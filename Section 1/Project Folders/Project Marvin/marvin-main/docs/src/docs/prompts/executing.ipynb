{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Executing Prompts\n",
    "\n",
    "Marvin makes executing one-off `task` or `chain` patterns dead simple. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running a `task`\n",
    "\n",
    "Once you have a prompt defined, fire it off with your chosen LLM asyncronously like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, you are correct! In traditional Euclidean geometry, the angles of a triangle always add up to 180 degrees. However, there are indeed other types of geometries where this is not the case. One such example is non-Euclidean geometry, which includes hyperbolic and elliptic geometries. In hyperbolic geometry, the angles of a triangle add up to less than 180 degrees, while in elliptic geometry, the angles add up to more than 180 degrees. These non-Euclidean geometries have their own unique properties and are studied in mathematics and physics.\n"
     ]
    }
   ],
   "source": [
    "from marvin.prompts.library import System, User, ChainOfThought\n",
    "from marvin.engine.language_models import ChatLLM\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "class ExpertSystem(System):\n",
    "    content: str = (\n",
    "        \"You are a world-class expert on {{topic}}. \"\n",
    "        \"When asked questions about {{topic}}, you answer correctly. \"\n",
    "        \"You only answer questions about {{topic}}. \"\n",
    "    )\n",
    "    topic: Optional[str]\n",
    "\n",
    "\n",
    "class Tutor(System):\n",
    "    content: str = (\n",
    "        \"When you give an answer, you modulate your response based on the \"\n",
    "        \"inferred knowledge of the user. \"\n",
    "        \"Your student's name is {{name}}. \"\n",
    "    )\n",
    "    name: str = \"not provided\"\n",
    "\n",
    "\n",
    "response = await ChatLLM()(\n",
    "    (\n",
    "        ExpertSystem()\n",
    "        | Tutor()\n",
    "        | User(\n",
    "            \"I heard that there are types of geometries when the angles don't add up to\"\n",
    "            \" 180?\"\n",
    "        )\n",
    "        | ChainOfThought()\n",
    "    ).render(topic=\"geometry\", name=\"Adam\")\n",
    ")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running a `chain`\n",
    "\n",
    "Of course, some applications require LLMs to run in an iterated loop so that it can deduce\n",
    "its next actions and take them. We've got you covered. Import an Executor (or create your own) and hit start."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"admonition abstract\">\n",
    "  <p class=\"admonition-title\">Jargon Alert!</p>\n",
    "  <p>\n",
    "    An `executor` here is a fancy phrase for a `while` or `for` loop under the context of a conversation with an LLM.\n",
    "    Below, `OpenAIExectutor` is a bare-bones implementation of 'if you get back a function call, call it, and pass the \n",
    "    answer back'. \n",
    "  </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from marvin.prompts.library import System, ChainOfThought, User\n",
    "from marvin.engine.executors import OpenAIExecutor\n",
    "from marvin.prompts import render_prompts\n",
    "\n",
    "\n",
    "def write_code(language: str, code: str) -> str:\n",
    "    \"\"\"A function that writes code in `language` to accomplish task\"\"\"\n",
    "\n",
    "\n",
    "response = await OpenAIExecutor(functions=[write_code]).start(\n",
    "    prompts=render_prompts(\n",
    "        System(content=\"You're an expert on {{subject}}.\")\n",
    "        | User(\n",
    "            content=\"I need to know how to write a function in {{subject}} to {{task}}\"\n",
    "        )\n",
    "        | ChainOfThought(),  # Tell the LLM to think step by step\n",
    "        {\"subject\": \"python\", \"task\": \"calculate the nth fibonacci number\"},\n",
    "    )\n",
    ")\n",
    "\n",
    "print(response[-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Here is a Python function that calculates the nth Fibonacci number:\n",
    "\n",
    "```python\n",
    "def fibonacci(n):\n",
    "    if n <= 0:\n",
    "        return \"Invalid input\"\n",
    "    elif n == 1:\n",
    "        return 0\n",
    "    elif n == 2:\n",
    "        return 1\n",
    "    else:\n",
    "        return fibonacci(n-1) + fibonacci(n-2)\n",
    "```\n",
    "\n",
    "To use this function, you can simply call it with the desired value of `n`:\n",
    "\n",
    "```python\n",
    "result = fibonacci(5)\n",
    "print(result)  # Output: 3\n",
    "```\n",
    "\n",
    "This will calculate and print the 5th Fibonacci number, which is 3.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
