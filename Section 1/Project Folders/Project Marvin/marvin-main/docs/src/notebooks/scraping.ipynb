{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "889a83c5",
   "metadata": {},
   "source": [
    "# Web Scraping\n",
    "\n",
    "## Marvin lets you build web scrapers that automatically *evolve with* your source material.\n",
    "\n",
    "One of the hardest parts of webscraping at scale is having to maintain custom code for nearly every page. If you're trying to monitor and extract new products from, say, Apple, Amazon, eBay, etc. you're on the hook for writing new code for each page. When they change their code, your pipeline breaks, and you lose your data for that run.  Large Language Models can deduce, reason, and infer where in the webpage your desired data lives. As your source material's schema changes, LLMs can reason where to find the new data, instead of failing. \n",
    "\n",
    "## Define your data model and let Marvin *infer* and *deduce* it from the source material."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "144f3bd6",
   "metadata": {},
   "source": [
    "We'll first define our data model using Pydantic. Say we have a signup for our website, wherein a user adds their work email to our 'Contact Us' page.\n",
    "We want to learn more things about that company so that we can better lead score or customize our outreach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a72c6052",
   "metadata": {},
   "outputs": [],
   "source": [
    "import marvin\n",
    "from pydantic import BaseModel, Field\n",
    "from enum import Enum\n",
    "\n",
    "\n",
    "class CompanyType(Enum):\n",
    "    startup = \"startup\"\n",
    "    scaleup = \"scaleup\"\n",
    "    enterprise = \"enterprise\"\n",
    "\n",
    "\n",
    "@marvin.ai_model\n",
    "class Company(BaseModel):\n",
    "    name: str = Field(..., description=\"Company name\")\n",
    "    description_short: str\n",
    "    description_long: str\n",
    "    industries: list[str]\n",
    "    type: CompanyType"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "96e66fff",
   "metadata": {},
   "source": [
    "Now we get an email from ford@prefect.io - a company that's not in our database. Our team is trying cutomize our messaging for enterprise users so we'll fire off a request to www.prefect.io and see what comes back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfc48c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"Prefect\",\n",
      "  \"description_short\": \"The New Standard in Dataflow Automation\",\n",
      "  \"description_long\": \"Prefect is a modern workflow orchestration tool for coordinating all of your data tools. Orchestrate and observe your dataflow using Prefect's open source Python library, the glue of the modern data stack. Scheduling, executing and visualizing your data workflows has never been easier.\",\n",
      "  \"industries\": [\"Dataflow Automation\", \"Workflow Orchestration\", \"Data Tools\"],\n",
      "  \"type\": \"startup\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "\n",
    "# Get the text from the Apple website\n",
    "soup = bs(requests.get(\"https://www.prefect.io\").content, \"html.parser\")\n",
    "\n",
    "soup.get_text(strip=True, separator=\" \")\n",
    "\n",
    "# Pass the text to the model\n",
    "company = Company(soup.get_text(strip=True, separator=\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3242d92b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3059ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
